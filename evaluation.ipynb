{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cv2D-I7_vVHn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import (\n",
        "    roc_curve, auc, silhouette_score, calinski_harabasz_score,\n",
        "    davies_bouldin_score, adjusted_rand_score, normalized_mutual_info_score\n",
        ")\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.saving import register_keras_serializable\n",
        "from fpdf import FPDF\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_2SWDwVwKrq",
        "outputId": "087ecc8c-5528-4b52-ce85-42819dce86ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Loaded 50 images of shape (64, 64, 3)\n"
          ]
        }
      ],
      "source": [
        "# Data configuration\n",
        "base_dir = \"\"\n",
        "data_dir = f'{base_dir}evaluation-data'  # Update this path to your data directory\n",
        "img_size = (64, 64)\n",
        "num_channels = 3\n",
        "file_ext = \".jpeg\"\n",
        "\n",
        "# Model paths - Update these paths to your actual model files\n",
        "MODEL_PATHS = {\n",
        "    'CAE': f'{base_dir}models/cae_model_final.h5',\n",
        "    'VAE': f'{base_dir}models/vae_model_final.h5',\n",
        "    'AAE': f'{base_dir}models/aae_model_final.h5'\n",
        "}\n",
        "\n",
        "# True labels for evaluation (update based on your actual data structure)\n",
        "# Assuming 10 images per person, 5 people\n",
        "TRUE_LABELS = np.repeat(np.arange(5), 10)  # [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,...]\n",
        "PERSON_NAMES = ['Alexis Putellas', 'Karim Benzema', 'Emma Watson', 'Jack Grealish', 'Erling Haaland']\n",
        "\n",
        "def load_data(data_dir):\n",
        "    \"\"\"\n",
        "    Load and preprocess images from directory\n",
        "\n",
        "    Returns:\n",
        "        np.array: Normalized images array of shape (n_samples, height, width, channels)\n",
        "    \"\"\"\n",
        "    file_names = [f for f in os.listdir(data_dir) if f.endswith(file_ext)]\n",
        "    file_names.sort()\n",
        "\n",
        "    images = np.zeros((len(file_names), img_size[0], img_size[1], num_channels), dtype=np.float32)\n",
        "\n",
        "    for i, file_name in enumerate(file_names):\n",
        "        img = Image.open(os.path.join(data_dir, file_name))\n",
        "        img = img.resize(img_size)\n",
        "        img = np.array(img, dtype=np.float32) / 255.0\n",
        "        images[i] = img\n",
        "\n",
        "    print(f\"Loaded {len(images)} images of shape {images.shape[1:]}\")\n",
        "    return images\n",
        "\n",
        "# Load data\n",
        "print(\"Loading data...\")\n",
        "x_manual = load_data(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbiIQ8C-FGhn",
        "outputId": "05e000ab-52df-4072-d110-175739c037bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading models...\n",
            "✓ Loaded CAE model from models/cae_model_final.h5\n",
            "WARNING:tensorflow:From c:\\Users\\fayez\\Desktop\\HLCV Project\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "✓ Loaded VAE model from models/vae_model_final.h5\n",
            "\n",
            "Extracting embeddings...\n",
            "✓ Extracted CAE embeddings: (50, 64, 64, 3)\n",
            "✓ Extracted VAE embeddings: (50, 64, 64, 3)\n"
          ]
        }
      ],
      "source": [
        "@register_keras_serializable()\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "class VAELossLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        encoder_inputs, outputs, z_mean, z_log_var = inputs\n",
        "\n",
        "        reconstruction_loss = tf.reduce_sum(tf.square(encoder_inputs - outputs), axis=[1, 2, 3])\n",
        "        kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
        "        total_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "        self.add_loss(total_loss)\n",
        "        return outputs\n",
        "\n",
        "def load_models():\n",
        "    \"\"\"\n",
        "    Load all available models\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of loaded models\n",
        "    \"\"\"\n",
        "    models = {}\n",
        "\n",
        "    for model_name, model_path in MODEL_PATHS.items():\n",
        "        if os.path.exists(model_path):\n",
        "            try:\n",
        "                if model_name == 'VAE':\n",
        "                    # For VAE, we need the encoder part\n",
        "                    vae_model = load_model(model_path, compile=False, custom_objects={'VAELossLayer': VAELossLayer})\n",
        "                    models[model_name] = vae_model\n",
        "                else:\n",
        "                    models[model_name] = load_model(model_path, compile=False)\n",
        "                print(f\"✓ Loaded {model_name} model from {model_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"✗ Failed to load {model_name} model: {e}\")\n",
        "        else:\n",
        "            print(f\"⚠ {model_name} model not found at {model_path}\")\n",
        "\n",
        "    return models\n",
        "\n",
        "def extract_embeddings(models, data):\n",
        "    \"\"\"\n",
        "    Extract embeddings from all models\n",
        "\n",
        "    Args:\n",
        "        models (dict): Dictionary of loaded models\n",
        "        data (np.array): Input images\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of embeddings for each model\n",
        "    \"\"\"\n",
        "    embeddings = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        try:\n",
        "            if model_name == 'VAE':\n",
        "                # For VAE, extract latent space embeddings (z_mean)\n",
        "                encoder_output = model.predict(data, verbose=0)\n",
        "                if isinstance(encoder_output, list) and len(encoder_output) >= 3:\n",
        "                    # Assuming VAE returns [reconstruction, z_mean, z_log_var]\n",
        "                    embeddings[model_name] = encoder_output[1]  # z_mean\n",
        "                else:\n",
        "                    # If VAE returns different format\n",
        "                    embeddings[model_name] = encoder_output\n",
        "            else:\n",
        "                # For CAE and AAE, extract encoder output\n",
        "                # You might need to adjust this based on your model architecture\n",
        "                embeddings[model_name] = model.predict(data, verbose=0)\n",
        "\n",
        "            print(f\"✓ Extracted {model_name} embeddings: {embeddings[model_name].shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Failed to extract {model_name} embeddings: {e}\")\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Load models and extract embeddings\n",
        "print(\"\\nLoading models...\")\n",
        "models = load_models()\n",
        "\n",
        "print(\"\\nExtracting embeddings...\")\n",
        "embeddings = extract_embeddings(models, x_manual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SnZXLJz0FI_V"
      },
      "outputs": [],
      "source": [
        "class ModelEvaluator:\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation class\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embeddings, true_labels, person_names):\n",
        "        self.embeddings = embeddings\n",
        "        self.true_labels = true_labels\n",
        "        self.person_names = person_names\n",
        "        self.results = {}\n",
        "\n",
        "    def compute_similarity_metrics(self):\n",
        "        \"\"\"\n",
        "        Compute various similarity metrics between embeddings\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"SIMILARITY METRICS ANALYSIS\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        similarity_results = {}\n",
        "\n",
        "        for model_name, emb in self.embeddings.items():\n",
        "            # Flatten embeddings if needed\n",
        "            if len(emb.shape) > 2:\n",
        "                emb = emb.reshape(emb.shape[0], -1)\n",
        "\n",
        "            # Compute pairwise similarities\n",
        "            cosine_sim = cosine_similarity(emb)\n",
        "            euclidean_dist = euclidean_distances(emb)\n",
        "\n",
        "            # Intra-class vs Inter-class similarities\n",
        "            intra_class_sims = []\n",
        "            inter_class_sims = []\n",
        "\n",
        "            for i in range(len(self.true_labels)):\n",
        "                for j in range(i+1, len(self.true_labels)):\n",
        "                    sim = cosine_sim[i, j]\n",
        "                    if self.true_labels[i] == self.true_labels[j]:\n",
        "                        intra_class_sims.append(sim)\n",
        "                    else:\n",
        "                        inter_class_sims.append(sim)\n",
        "\n",
        "            # Compute statistics\n",
        "            intra_mean = np.mean(intra_class_sims)\n",
        "            inter_mean = np.mean(inter_class_sims)\n",
        "            separation_score = intra_mean - inter_mean  # Higher is better\n",
        "\n",
        "            similarity_results[model_name] = {\n",
        "                'intra_class_similarity': intra_mean,\n",
        "                'inter_class_similarity': inter_mean,\n",
        "                'separation_score': separation_score,\n",
        "                'cosine_similarity_matrix': cosine_sim,\n",
        "                'euclidean_distance_matrix': euclidean_dist\n",
        "            }\n",
        "\n",
        "            print(f\"\\n{model_name} Model:\")\n",
        "            print(f\"  Intra-class similarity: {intra_mean:.4f}\")\n",
        "            print(f\"  Inter-class similarity: {inter_mean:.4f}\")\n",
        "            print(f\"  Separation score: {separation_score:.4f}\")\n",
        "\n",
        "        return similarity_results\n",
        "\n",
        "    def compute_clustering_metrics(self, n_clusters=5):\n",
        "        \"\"\"\n",
        "        Evaluate clustering performance using multiple algorithms\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"CLUSTERING PERFORMANCE ANALYSIS\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        clustering_results = {}\n",
        "\n",
        "        # Clustering algorithms to evaluate\n",
        "        clustering_algorithms = {\n",
        "            'KMeans': KMeans(n_clusters=n_clusters, random_state=42),\n",
        "            'SpectralClustering': SpectralClustering(n_clusters=n_clusters, random_state=42),\n",
        "            'GMM': GaussianMixture(n_components=n_clusters, random_state=42),\n",
        "            'AgglomerativeClustering': AgglomerativeClustering(n_clusters=n_clusters)\n",
        "        }\n",
        "\n",
        "        for model_name, emb in self.embeddings.items():\n",
        "            # Flatten embeddings if needed\n",
        "            if len(emb.shape) > 2:\n",
        "                emb = emb.reshape(emb.shape[0], -1)\n",
        "\n",
        "            # Standardize embeddings\n",
        "            scaler = StandardScaler()\n",
        "            emb_scaled = scaler.fit_transform(emb)\n",
        "\n",
        "            model_clustering_results = {}\n",
        "\n",
        "            for alg_name, algorithm in clustering_algorithms.items():\n",
        "                try:\n",
        "                    if alg_name == 'GMM':\n",
        "                        predicted_labels = algorithm.fit_predict(emb_scaled)\n",
        "                    else:\n",
        "                        predicted_labels = algorithm.fit_predict(emb_scaled)\n",
        "\n",
        "                    # Compute clustering metrics\n",
        "                    silhouette = silhouette_score(emb_scaled, predicted_labels)\n",
        "                    calinski_harabasz = calinski_harabasz_score(emb_scaled, predicted_labels)\n",
        "                    davies_bouldin = davies_bouldin_score(emb_scaled, predicted_labels)\n",
        "\n",
        "                    # Compute external metrics (if true labels available)\n",
        "                    if self.true_labels is not None:\n",
        "                        ari = adjusted_rand_score(self.true_labels, predicted_labels)\n",
        "                        nmi = normalized_mutual_info_score(self.true_labels, predicted_labels)\n",
        "                    else:\n",
        "                        ari = nmi = None\n",
        "\n",
        "                    model_clustering_results[alg_name] = {\n",
        "                        'predicted_labels': predicted_labels,\n",
        "                        'silhouette_score': silhouette,\n",
        "                        'calinski_harabasz_score': calinski_harabasz,\n",
        "                        'davies_bouldin_score': davies_bouldin,\n",
        "                        'adjusted_rand_score': ari,\n",
        "                        'normalized_mutual_info': nmi\n",
        "                    }\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  Failed to run {alg_name} on {model_name}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            clustering_results[model_name] = model_clustering_results\n",
        "\n",
        "            # Print results\n",
        "            print(f\"\\n{model_name} Model Clustering Results:\")\n",
        "            for alg_name, metrics in model_clustering_results.items():\n",
        "                print(f\"  {alg_name}:\")\n",
        "                print(f\"    Silhouette Score: {metrics['silhouette_score']:.4f}\")\n",
        "                print(f\"    Calinski-Harabasz Score: {metrics['calinski_harabasz_score']:.2f}\")\n",
        "                print(f\"    Davies-Bouldin Score: {metrics['davies_bouldin_score']:.4f}\")\n",
        "                if metrics['adjusted_rand_score'] is not None:\n",
        "                    print(f\"    Adjusted Rand Index: {metrics['adjusted_rand_score']:.4f}\")\n",
        "                    print(f\"    Normalized Mutual Info: {metrics['normalized_mutual_info']:.4f}\")\n",
        "\n",
        "        return clustering_results\n",
        "\n",
        "    def compute_reconstruction_quality(self, models, original_images):\n",
        "        \"\"\"\n",
        "        Evaluate reconstruction quality for autoencoders\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"RECONSTRUCTION QUALITY ANALYSIS\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        reconstruction_results = {}\n",
        "\n",
        "        for model_name, model in models.items():\n",
        "            try:\n",
        "                # Get reconstructions\n",
        "                reconstructions = model.predict(original_images, verbose=0)\n",
        "\n",
        "                # Compute metrics\n",
        "                mse = np.mean((original_images - reconstructions) ** 2)\n",
        "                psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n",
        "\n",
        "                # Structural similarity (simplified)\n",
        "                ssim_scores = []\n",
        "                for i in range(len(original_images)):\n",
        "                    orig = original_images[i]\n",
        "                    recon = reconstructions[i]\n",
        "\n",
        "                    # Simple correlation-based similarity\n",
        "                    correlation = np.corrcoef(orig.flatten(), recon.flatten())[0, 1]\n",
        "                    ssim_scores.append(correlation)\n",
        "\n",
        "                avg_ssim = np.mean(ssim_scores)\n",
        "\n",
        "                reconstruction_results[model_name] = {\n",
        "                    'reconstructions': reconstructions,\n",
        "                    'mse': mse,\n",
        "                    'psnr': psnr,\n",
        "                    'avg_ssim': avg_ssim\n",
        "                }\n",
        "\n",
        "                print(f\"\\n{model_name} Model:\")\n",
        "                print(f\"  MSE: {mse:.6f}\")\n",
        "                print(f\"  PSNR: {psnr:.2f} dB\")\n",
        "                print(f\"  Average SSIM: {avg_ssim:.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Failed to evaluate reconstruction for {model_name}: {e}\")\n",
        "\n",
        "        return reconstruction_results\n",
        "\n",
        "    def generate_comprehensive_report(self):\n",
        "        \"\"\"\n",
        "        Generate a comprehensive evaluation report\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"COMPREHENSIVE MODEL EVALUATION REPORT\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Run all evaluations\n",
        "        similarity_results = self.compute_similarity_metrics()\n",
        "        clustering_results = self.compute_clustering_metrics()\n",
        "\n",
        "        # Store results\n",
        "        self.results = {\n",
        "            'similarity': similarity_results,\n",
        "            'clustering': clustering_results\n",
        "        }\n",
        "\n",
        "        # Summary comparison\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"SUMMARY COMPARISON\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Create comparison table\n",
        "        comparison_data = []\n",
        "        for model_name in self.embeddings.keys():\n",
        "            if model_name in similarity_results and model_name in clustering_results:\n",
        "                row = {\n",
        "                    'Model': model_name,\n",
        "                    'Separation Score': similarity_results[model_name]['separation_score'],\n",
        "                    'Best Silhouette': max([metrics['silhouette_score']\n",
        "                                          for metrics in clustering_results[model_name].values()]),\n",
        "                    'Best ARI': max([metrics['adjusted_rand_score']\n",
        "                                   for metrics in clustering_results[model_name].values()\n",
        "                                   if metrics['adjusted_rand_score'] is not None] or [0])\n",
        "                }\n",
        "                comparison_data.append(row)\n",
        "\n",
        "        # Print comparison\n",
        "        print(\"\\nModel Performance Summary:\")\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"{'Model':<15} {'Separation':<12} {'Best Silhouette':<15} {'Best ARI':<10}\")\n",
        "        print(\"-\" * 60)\n",
        "        for row in comparison_data:\n",
        "            print(f\"{row['Model']:<15} {row['Separation Score']:<12.4f} {row['Best Silhouette']:<15.4f} {row['Best ARI']:<10.4f}\")\n",
        "\n",
        "        return self.results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QjUmLd-HFLt7"
      },
      "outputs": [],
      "source": [
        "def plot_embeddings_tsne(embeddings, true_labels, person_names):\n",
        "    \"\"\"\n",
        "    Visualize embeddings using t-SNE\n",
        "    \"\"\"\n",
        "    print(\"\\nGenerating t-SNE visualizations...\")\n",
        "\n",
        "    n_models = len(embeddings)\n",
        "    fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 5))\n",
        "    if n_models == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(person_names)))\n",
        "\n",
        "    for idx, (model_name, emb) in enumerate(embeddings.items()):\n",
        "        # Flatten embeddings if needed\n",
        "        if len(emb.shape) > 2:\n",
        "            emb = emb.reshape(emb.shape[0], -1)\n",
        "\n",
        "        # Apply t-SNE\n",
        "        tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(emb)-1))\n",
        "        emb_2d = tsne.fit_transform(emb)\n",
        "\n",
        "        # Plot\n",
        "        ax = axes[idx]\n",
        "        for i, person in enumerate(person_names):\n",
        "            mask = true_labels == i\n",
        "            ax.scatter(emb_2d[mask, 0], emb_2d[mask, 1],\n",
        "                      c=[colors[i]], label=person, alpha=0.7, s=50)\n",
        "\n",
        "        ax.set_title(f'{model_name} Embeddings (t-SNE)', fontsize=14)\n",
        "        ax.set_xlabel('t-SNE 1')\n",
        "        ax.set_ylabel('t-SNE 2')\n",
        "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_similarity_matrices(similarity_results):\n",
        "    \"\"\"\n",
        "    Plot similarity matrices for all models\n",
        "    \"\"\"\n",
        "    print(\"\\nGenerating similarity matrices...\")\n",
        "\n",
        "    n_models = len(similarity_results)\n",
        "    fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 5))\n",
        "    if n_models == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for idx, (model_name, results) in enumerate(similarity_results.items()):\n",
        "        ax = axes[idx]\n",
        "        im = ax.imshow(results['cosine_similarity_matrix'], cmap='viridis', aspect='auto')\n",
        "        ax.set_title(f'{model_name} Cosine Similarity Matrix')\n",
        "        ax.set_xlabel('Sample Index')\n",
        "        ax.set_ylabel('Sample Index')\n",
        "        plt.colorbar(im, ax=ax)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_reconstructions(reconstruction_results, original_images, n_samples=5):\n",
        "    \"\"\"\n",
        "    Plot original vs reconstructed images\n",
        "    \"\"\"\n",
        "    print(\"\\nGenerating reconstruction comparisons...\")\n",
        "\n",
        "    n_models = len(reconstruction_results)\n",
        "    fig, axes = plt.subplots(n_models, 2*n_samples, figsize=(2*n_samples*2, n_models*2))\n",
        "\n",
        "    if n_models == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for model_idx, (model_name, results) in enumerate(reconstruction_results.items()):\n",
        "        reconstructions = results['reconstructions']\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            # Original image\n",
        "            ax_orig = axes[model_idx, 2*i]\n",
        "            ax_orig.imshow(original_images[i])\n",
        "            ax_orig.set_title(f'Original {i+1}' if model_idx == 0 else '')\n",
        "            ax_orig.axis('off')\n",
        "\n",
        "            # Reconstructed image\n",
        "            ax_recon = axes[model_idx, 2*i + 1]\n",
        "            ax_recon.imshow(reconstructions[i])\n",
        "            ax_recon.set_title(f'Reconstructed {i+1}' if model_idx == 0 else '')\n",
        "            ax_recon.axis('off')\n",
        "\n",
        "        # Add model name on the left\n",
        "        axes[model_idx, 0].text(-0.1, 0.5, model_name, transform=axes[model_idx, 0].transAxes,\n",
        "                               rotation=90, va='center', ha='right', fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_clustering_performance(clustering_results):\n",
        "    \"\"\"\n",
        "    Plot clustering performance metrics\n",
        "    \"\"\"\n",
        "    print(\"\\nGenerating clustering performance plots...\")\n",
        "\n",
        "    metrics = ['silhouette_score', 'adjusted_rand_score', 'normalized_mutual_info']\n",
        "    metric_names = ['Silhouette Score', 'Adjusted Rand Index', 'Normalized Mutual Info']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    for metric_idx, (metric, metric_name) in enumerate(zip(metrics, metric_names)):\n",
        "        ax = axes[metric_idx]\n",
        "\n",
        "        model_names = list(clustering_results.keys())\n",
        "        algorithm_names = list(clustering_results[model_names[0]].keys())\n",
        "\n",
        "        x = np.arange(len(algorithm_names))\n",
        "        width = 0.25\n",
        "\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            values = []\n",
        "            for alg_name in algorithm_names:\n",
        "                value = clustering_results[model_name][alg_name][metric]\n",
        "                values.append(value if value is not None else 0)\n",
        "\n",
        "            ax.bar(x + i*width, values, width, label=model_name, alpha=0.8)\n",
        "\n",
        "        ax.set_xlabel('Clustering Algorithm')\n",
        "        ax.set_ylabel(metric_name)\n",
        "        ax.set_title(f'{metric_name} by Model and Algorithm')\n",
        "        ax.set_xticks(x + width)\n",
        "        ax.set_xticklabels(algorithm_names, rotation=45)\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Lp59he_9FO-r"
      },
      "outputs": [],
      "source": [
        "def main_evaluation():\n",
        "    \"\"\"\n",
        "    Run comprehensive evaluation\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"STARTING COMPREHENSIVE MODEL EVALUATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if not embeddings:\n",
        "        print(\"No embeddings available for evaluation!\")\n",
        "        return\n",
        "\n",
        "    # Initialize evaluator\n",
        "    evaluator = ModelEvaluator(embeddings, TRUE_LABELS, PERSON_NAMES)\n",
        "\n",
        "    # Run comprehensive evaluation\n",
        "    results = evaluator.generate_comprehensive_report()\n",
        "\n",
        "    # Generate visualizations\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"GENERATING VISUALIZATIONS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # t-SNE visualization\n",
        "    plot_embeddings_tsne(embeddings, TRUE_LABELS, PERSON_NAMES)\n",
        "\n",
        "    # Similarity matrices\n",
        "    if 'similarity' in results:\n",
        "        plot_similarity_matrices(results['similarity'])\n",
        "\n",
        "    # Clustering performance\n",
        "    if 'clustering' in results:\n",
        "        plot_clustering_performance(results['clustering'])\n",
        "\n",
        "    # Reconstruction quality (if models available)\n",
        "    if models:\n",
        "        reconstruction_results = evaluator.compute_reconstruction_quality(models, x_manual[:10])\n",
        "        if reconstruction_results:\n",
        "            plot_reconstructions(reconstruction_results, x_manual[:10])\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EVALUATION COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3pKQFZ9FPTL",
        "outputId": "a8e299d8-aa76-4766-bbfb-f7e76693efeb"
      },
      "outputs": [],
      "source": [
        "def save_results_to_pdf(results, filename=\"evaluation_results.pdf\"):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    # If results is a dict or list, convert to string line-by-line\n",
        "    if isinstance(results, (dict, list)):\n",
        "        lines = str(results).splitlines()\n",
        "    else:\n",
        "        lines = str(results).split('\\n')\n",
        "\n",
        "    for line in lines:\n",
        "        pdf.multi_cell(0, 10, txt=line)\n",
        "\n",
        "    pdf.output(filename)\n",
        "    print(f\"\\nEvaluation results saved to {filename}\")\n",
        "\n",
        "# Example usage\n",
        "# evaluation_results = main_evaluation()\n",
        "# save_results_to_pdf(evaluation_results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
